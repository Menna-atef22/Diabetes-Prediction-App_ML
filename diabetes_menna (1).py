# -*- coding: utf-8 -*-
"""Diabetes_Menna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vK1Utzq9VVvzOk407Ox2fnaKqVnS8Zyg
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d akshaydattatraykhare/diabetes-dataset

!unzip /content/diabetes-dataset.zip

dataset = pd.read_csv('/content/diabetes.csv', na_values= ['?'])
dataset.head(10)

dataset.shape

dataset.isnull().sum()

dataset.info()

dataset.describe( include ='all')

dataset["Insulin"].value_counts()

normal_insulin = dataset[dataset['Outcome'] == 0]['Insulin']
diabetic_insulin = dataset[dataset['Outcome'] == 1]['Insulin']

print("Insulin values in NORMAL cases (Outcome=0):")
print(normal_insulin.unique())


print("\nInsulin values in DIABETIC cases (Outcome=1):")
print(diabetic_insulin.unique())

insulin_normal = dataset[(dataset['Outcome'] == 0) & (dataset['Insulin'] != 0)]['Insulin']
insulin_diabetic = dataset[(dataset['Outcome'] == 1) & (dataset['Insulin'] != 0)]['Insulin']

median_normal_insulin = insulin_normal.median()
median_diabetic_insulin = insulin_diabetic.median()

print(f"Median Insulin (Normal): {median_normal_insulin}")
print(f"Median Insulin (Diabetic): {median_diabetic_insulin}")

dataset.loc[(dataset['Outcome'] == 0) &  ((dataset['Insulin'] < 10) | (dataset['Insulin'] > 250)) &  (dataset['Insulin'] != 0),'Insulin'] = median_normal_insulin
dataset.loc[ (dataset['Outcome'] == 1) & ((dataset['Insulin'] < 15) | (dataset['Insulin'] > 300)) & (dataset['Insulin'] != 0), 'Insulin'] = median_diabetic_insulin

mean_normal_insulin = dataset[(dataset['Outcome'] == 0) & (dataset['Insulin'] != 0)]['Insulin'].mean()
mean_diabetic_insulin = dataset[(dataset['Outcome'] == 1) & (dataset['Insulin'] != 0)]['Insulin'].mean()

dataset.loc[(dataset['Outcome'] == 0) & (dataset['Insulin'] == 0), 'Insulin'] = mean_normal_insulin
dataset.loc[(dataset['Outcome'] == 1) & (dataset['Insulin'] == 0), 'Insulin'] = mean_diabetic_insulin

dataset.describe()

dataset['Insulin'].value_counts()

glucose_normal = dataset[dataset['Outcome'] == 0]['Glucose']
glucose_diabetic = dataset[dataset['Outcome'] == 1]['Glucose']

print("Glucose values in NORMAL cases (Outcome=0):")
print(glucose_normal.unique())

print("\nGlucose values in DIABETIC cases (Outcome=1):")
print(glucose_diabetic.unique())

median_glucose_normal = dataset[(dataset['Outcome'] == 0) & (dataset['Glucose'] != 0)]['Glucose'].median()
median_glucose_diabetic = dataset[(dataset['Outcome'] == 1) & (dataset['Glucose'] != 0)]['Glucose'].median()

dataset.loc[(dataset['Outcome'] == 0) & ((dataset['Glucose'] < 70) | (dataset['Glucose'] > 140)) &  (dataset['Glucose'] != 0),'Glucose'] = median_glucose_normal

dataset.loc[ (dataset['Outcome'] == 1) & ((dataset['Glucose'] < 80) | (dataset['Glucose'] > 200)) & (dataset['Glucose'] != 0),'Glucose'] = median_glucose_diabetic

mean_glucose_normal = dataset[(dataset['Outcome'] == 0) & (dataset['Glucose'] != 0)]['Glucose'].mean()
mean_glucose_diabetic = dataset[(dataset['Outcome'] == 1) & (dataset['Glucose'] != 0)]['Glucose'].mean()

dataset.loc[(dataset['Outcome'] == 0) & (dataset['Glucose'] == 0), 'Glucose'] = mean_glucose_normal
dataset.loc[(dataset['Outcome'] == 1) & (dataset['Glucose'] == 0), 'Glucose'] = mean_glucose_diabetic

normal_skin_thickness = dataset[dataset['Outcome'] == 0]['SkinThickness']
diabetic_skin_thickness = dataset[dataset['Outcome'] == 1]['SkinThickness']

print("SkinThickness values in NORMAL cases (Outcome=0):")
print(normal_skin_thickness.unique())

print("\nSkinThickness values in DIABETIC cases (Outcome=1):")
print(diabetic_skin_thickness.unique())

normal_nonzero = dataset[(dataset['Outcome'] == 0 )& (dataset['SkinThickness'] != 0)]
diabetic_nonzero = dataset[(dataset['Outcome'] == 1 )& (dataset['SkinThickness'] != 0)]

median_normal = normal_nonzero['SkinThickness'].median()
median_diabetic = diabetic_nonzero['SkinThickness'].median()

print(f"Median SkinThickness (Normal): {median_normal}")
print(f"Median SkinThickness (Diabetic): {median_diabetic}")

dataset.loc[ (dataset['Outcome'] == 0) &  ((dataset['SkinThickness'] < 10) | (dataset['SkinThickness'] > 40)) & (dataset['SkinThickness'] != 0), 'SkinThickness'] = median_normal
dataset.loc[ (dataset['Outcome'] == 1) &  ((dataset['SkinThickness'] < 15) | (dataset['SkinThickness'] > 50)) &  (dataset['SkinThickness'] != 0), 'SkinThickness'] = median_diabetic

mean_normal = dataset[(dataset['Outcome'] == 0) & (dataset['SkinThickness'] != 0)]['SkinThickness'].mean()
mean_diabetic = dataset[(dataset['Outcome'] == 1) & (dataset['SkinThickness'] != 0)]['SkinThickness'].mean()

dataset.loc[(dataset['Outcome'] == 0) & (dataset['SkinThickness'] == 0), 'SkinThickness'] = mean_normal
dataset.loc[(dataset['Outcome'] == 1) & (dataset['SkinThickness'] == 0), 'SkinThickness'] = mean_diabetic

print(f"Mean (Normal): {mean_normal:.2f}")
print(f"Mean (Diabetic): {mean_diabetic:.2f}")

dataset.describe()

plt.figure(figsize=(10,5))
sns.kdeplot(dataset[dataset['Outcome'] == 0]['SkinThickness'], label='Normal', fill=True)
sns.kdeplot(dataset[dataset['Outcome'] == 1]['SkinThickness'], label='Diabetic', fill=True)
plt.title("SkinThickness Distribution After Cleaning")
plt.legend()
plt.show()

correlation_matrix = dataset.corr()
correlation_with_outcome = correlation_matrix['Outcome']
sorted_correlation = correlation_with_outcome.sort_values(ascending=False)
print("Correlation with 'Outcome' (Sorted from Largest to Smallest):")
sorted_correlation

dataset['BloodPressure'].unique()

bp_mean = dataset[dataset['BloodPressure'] != 0]['BloodPressure'].mean()

dataset.loc[dataset['BloodPressure'] == 0, 'BloodPressure'] = bp_mean

correlation_matrix = dataset.corr()
correlation_with_outcome = correlation_matrix['Outcome']
sorted_correlation = correlation_with_outcome.sort_values(ascending=False)
print("Correlation with 'Outcome' (Sorted from Largest to Smallest):")
sorted_correlation

mode_normal = dataset[(dataset['Outcome'] == 0) ]['Pregnancies'].unique()
mode_diabetic = dataset[(dataset['Outcome'] == 1)]['Pregnancies'].unique()

print(f"Mode (Normal): {mode_normal}")
print(f"Mode (Diabetic): {mode_diabetic}")

mode_normal = dataset[(dataset['Outcome'] == 0) & (dataset['Pregnancies'] <= 9)]['Pregnancies'].mode()[0]
mode_diabetic = dataset[(dataset['Outcome'] == 1) & (dataset['Pregnancies'] <= 9)]['Pregnancies'].mode()[0]

dataset.loc[(dataset['Outcome'] == 0) & (dataset['Pregnancies'] > 9), 'Pregnancies'] = mode_normal
dataset.loc[(dataset['Outcome'] == 1) & (dataset['Pregnancies'] > 13), 'Pregnancies'] = mode_diabetic

correlation_matrix = dataset.corr()
correlation_with_outcome = correlation_matrix['Outcome']
sorted_correlation = correlation_with_outcome.sort_values(ascending=False)
print("Correlation with 'Outcome' (Sorted from Largest to Smallest):")
sorted_correlation

normal_BMI = dataset[(dataset['Outcome'] == 0) ]['BMI'].unique()
Diabetic_BMI = dataset[(dataset['Outcome'] == 1)]['BMI'].unique()

print(f"\nnormal_BMI  (Normal):\n {normal_BMI}")
print(f"\nDiabetic_BMI (Diabetic):\n {Diabetic_BMI}")

median_normal_bmi = dataset[(dataset['Outcome'] == 0) & (dataset['BMI'] != 0)]['BMI'].median()
median_diabetic_bmi = dataset[(dataset['Outcome'] == 1) & (dataset['BMI'] != 0)]['BMI'].median()

dataset.loc[(dataset['Outcome'] == 0) & (dataset['BMI'] == 0), 'BMI'] = median_normal_bmi
dataset.loc[(dataset['Outcome'] == 1) & (dataset['BMI'] == 0), 'BMI'] = median_diabetic_bmi

correlation_matrix = dataset.corr()
correlation_with_outcome = correlation_matrix['Outcome']
sorted_correlation = correlation_with_outcome.sort_values(ascending=False)
print("Correlation with 'Outcome' (Sorted from Largest to Smallest):")
sorted_correlation

normal_Age = dataset[(dataset['Outcome'] == 0) ]['Age'].unique()
Diabetic_Age = dataset[(dataset['Outcome'] == 1)]['Age'].unique()

print(f"\nnormal_Age  (Normal):\n {normal_Age}")
print(f"\nDiabetic_Age (Diabetic):\n {Diabetic_Age}")

normal_DiabetesPedigreeFunction = dataset[(dataset['Outcome'] == 0) ]['DiabetesPedigreeFunction'].unique()
Diabetic_DiabetesPedigreeFunction = dataset[(dataset['Outcome'] == 1)]['DiabetesPedigreeFunction'].unique()

print(f"\nnormal_DiabetesPedigreeFunction  (Normal):\n {normal_DiabetesPedigreeFunction}")
print(f"\nDiabetic_DiabetesPedigreeFunction (Diabetic):\n {Diabetic_DiabetesPedigreeFunction}")

outcome_counts = dataset['Outcome'].value_counts()

print("Counts of Outcome (0 and 1):")
outcome_counts

X = dataset.drop('Outcome', axis=1)
y = dataset['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=52)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_train_scaled

models = {
    'LogisticRegression': LogisticRegression(),
    'KNN': KNeighborsClassifier(),
    'SVC': SVC(),
    'DecisionTree': DecisionTreeClassifier(),
    'RandomForest': RandomForestClassifier(),
    'XGBoost': XGBClassifier()
}

param_grids = {
    'LogisticRegression': {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},
    'KNN': {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],'weights': ['uniform', 'distance'],'metric': ['euclidean', 'manhattan']},
    'SVC': {'C': [0.001, 0.01, 0.1, 1, 10],'class_weight': [None, 'balanced'],'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},
    'DecisionTree': {'max_depth': [None, 3, 5, 7,10, 15, 20], 'min_samples_split': [2, 5, 10]},
    'RandomForest': {'n_estimators': [50, 100, 200, 300, 500], 'max_depth': [None, 3, 5, 7, 10]},
    'XGBoost': {'n_estimators': [50, 100, 200, 300, 500], 'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3], 'max_depth': [3, 5, 7, 10]}
}

best_models = {}
for model_name, model in models.items():
    print(f"\nRunning Grid Search for {model_name}...")
    grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='accuracy')
    grid_search.fit(X_train_scaled, y_train)

    print(f"Best parameters for {model_name}: {grid_search.best_params_}")
    print(f"Best cross-validation score for {model_name}: {grid_search.best_score_}")
    best_models[model_name] = grid_search.best_estimator_



print("\nEvaluating best models on the test set:")
for model_name, best_model in best_models.items():
    y_pred = best_model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Test set accuracy for {model_name}: {accuracy}")

#xXGBoost
xgb = XGBClassifier(learning_rate=0.01, max_depth=4, n_estimators=500)
xgb.fit(X_train_scaled, y_train)

train_preds = xgb.predict(X_train_scaled)
test_preds = xgb.predict(X_test_scaled)

train_acc = accuracy_score(y_train, train_preds)
test_acc = accuracy_score(y_test, test_preds)

print("Train Accuracy:", train_acc)
print("Test Accuracy:", test_acc)

print("\nClassification Report (Test Data):")
print(classification_report(y_test, test_preds))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, test_preds))

gap = train_acc - test_acc
print("Accuracy Gap:", gap)

from xgboost import plot_tree
fig, ax = plt.subplots(figsize=(50, 30))
plot_tree(xgb, num_trees=0, ax=ax, rankdir='LR')
plt.title("XGBoost Tree 0", fontsize=20)
plt.show()

!pip install streamlit
!pip install pyngrok
!pip install streamlit pyngrok scikit-learn pandas numpy matplotlib seaborn

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import pickle

url = 'https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv'
df = pd.read_csv(url)

X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


model = SVC(probability=True)
model.fit(X_train, y_train)

with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

from google.colab import files
files.download('model.pkl')

import pickle

with open('model.pkl', 'wb') as file:
    pickle.dump(model, file)